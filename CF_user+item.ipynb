{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f710c6de-cb3f-4cc6-aac2-9d01d94ce5de",
   "metadata": {},
   "source": [
    "# Memory-based Collaborative Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6bdeaf0b-6c04-4abe-85ca-26953b59d2ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ad08e86e-8338-4875-8fd5-66b8c734ad4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recall5(answer_df, submission_df):\n",
    "    \"\"\"\n",
    "    Calculate recall@5 for given dataframes.\n",
    "    \n",
    "    Parameters:\n",
    "    - answer_df: DataFrame containing the ground truth\n",
    "    - submission_df: DataFrame containing the predictions\n",
    "    \n",
    "    Returns:\n",
    "    - recall: Recall@5 value\n",
    "    \"\"\"\n",
    "    \n",
    "    primary_col = answer_df.columns[0]\n",
    "    secondary_col = answer_df.columns[1]\n",
    "    \n",
    "    # Check if each primary_col entry has exactly 5 secondary_col predictions\n",
    "    prediction_counts = submission_df.groupby(primary_col).size()\n",
    "    if not all(prediction_counts == 5):\n",
    "        raise ValueError(f\"Each {primary_col} should have exactly 5 {secondary_col} predictions.\")\n",
    "\n",
    "\n",
    "    # Check for NULL values in the predicted secondary_col\n",
    "    if submission_df[secondary_col].isnull().any():\n",
    "        raise ValueError(f\"Predicted {secondary_col} contains NULL values.\")\n",
    "    \n",
    "    # Check for duplicates in the predicted secondary_col for each primary_col\n",
    "    duplicated_preds = submission_df.groupby(primary_col).apply(lambda x: x[secondary_col].duplicated().any())\n",
    "    if duplicated_preds.any():\n",
    "        raise ValueError(f\"Predicted {secondary_col} contains duplicates for some {primary_col}.\")\n",
    "\n",
    "\n",
    "    # Filter the submission dataframe based on the primary_col present in the answer dataframe\n",
    "    submission_df = submission_df[submission_df[primary_col].isin(answer_df[primary_col])]\n",
    "    \n",
    "    # For each primary_col, get the top 5 predicted secondary_col values\n",
    "    top_5_preds = submission_df.groupby(primary_col).apply(lambda x: x[secondary_col].head(5).tolist()).to_dict()\n",
    "    \n",
    "    # Convert the answer_df to a dictionary for easier lookup\n",
    "    true_dict = answer_df.groupby(primary_col).apply(lambda x: x[secondary_col].tolist()).to_dict()\n",
    "    \n",
    "    \n",
    "    individual_recalls = []\n",
    "    for key, val in true_dict.items():\n",
    "        if key in top_5_preds:\n",
    "            correct_matches = len(set(true_dict[key]) & set(top_5_preds[key]))\n",
    "            individual_recall = correct_matches / min(len(val), 5) # 공정한 평가를 가능하게 위하여 분모(k)를 'min(len(val), 5)' 로 설정함 \n",
    "            individual_recalls.append(individual_recall)\n",
    "\n",
    "\n",
    "    recall = np.mean(individual_recalls)\n",
    "    \n",
    "    return recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7629772e-5dd6-4bfb-b118-4d67613ec18c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userID</th>\n",
       "      <th>articleID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>USER_0000</td>\n",
       "      <td>ARTICLE_2255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>USER_0000</td>\n",
       "      <td>ARTICLE_0411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>USER_0000</td>\n",
       "      <td>ARTICLE_2834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>USER_0000</td>\n",
       "      <td>ARTICLE_1033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>USER_0000</td>\n",
       "      <td>ARTICLE_2316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7070</th>\n",
       "      <td>USER_1420</td>\n",
       "      <td>ARTICLE_0030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7071</th>\n",
       "      <td>USER_1420</td>\n",
       "      <td>ARTICLE_0714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7072</th>\n",
       "      <td>USER_1420</td>\n",
       "      <td>ARTICLE_0614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7073</th>\n",
       "      <td>USER_1420</td>\n",
       "      <td>ARTICLE_1848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7074</th>\n",
       "      <td>USER_1420</td>\n",
       "      <td>ARTICLE_1732</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7075 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         userID     articleID\n",
       "0     USER_0000  ARTICLE_2255\n",
       "1     USER_0000  ARTICLE_0411\n",
       "2     USER_0000  ARTICLE_2834\n",
       "3     USER_0000  ARTICLE_1033\n",
       "4     USER_0000  ARTICLE_2316\n",
       "...         ...           ...\n",
       "7070  USER_1420  ARTICLE_0030\n",
       "7071  USER_1420  ARTICLE_0714\n",
       "7072  USER_1420  ARTICLE_0614\n",
       "7073  USER_1420  ARTICLE_1848\n",
       "7074  USER_1420  ARTICLE_1732\n",
       "\n",
       "[7075 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "view_log_train = pd.read_csv('data/view_log.csv')\n",
    "article_info = pd.read_csv('data/article_info.csv')\n",
    "submission = pd.read_csv('data/sample_submission.csv')\n",
    "\n",
    "# 사용자-기사 행렬 생성\n",
    "user_article_matrix = view_log_train.groupby(['userID', 'articleID']).size().unstack(fill_value=0)\n",
    "\n",
    "# 사용자 간의 유사성 계산\n",
    "user_similarity = cosine_similarity(user_article_matrix)\n",
    "item_similarity = cosine_similarity(user_article_matrix.T)\n",
    "\n",
    "# 추천 점수 계산\n",
    "user_predicted_scores = user_similarity.dot(user_article_matrix)\n",
    "item_predicted_scores = user_article_matrix.dot(item_similarity)\n",
    "\n",
    "alpha = 0.3\n",
    "predicted_scores = alpha * user_predicted_scores + (1-alpha) * item_predicted_scores\n",
    "\n",
    "predicted_scores.columns = user_article_matrix.columns\n",
    "\n",
    "# 각 사용자별 상위 5개 기사 추출 함수 정의\n",
    "def top5_article(df):\n",
    "    df_freq = df.value_counts(\"articleID\", ascending=False)[:5]\n",
    "    return df_freq\n",
    "\n",
    "df_freq = view_log_train.groupby(\"userID\").apply(top5_article).reset_index()\n",
    "\n",
    "# 각 userID 별로 5개의 행을 가지도록 부족한 행 추가\n",
    "user_groups = df_freq.groupby('userID')\n",
    "new_rows = []\n",
    "\n",
    "for userID, group in user_groups:\n",
    "    article_list = group['articleID'].to_list() # 각 사용자가 조회한 기사 리스트\n",
    "    temp = predicted_scores.loc[userID] # 해당 사용자의 기사별 예측 점수\n",
    "    article_list = list(set(temp.index) - set(article_list)) # 예측 점수 데이터에서 사용자가 이미 조회한 기사 제외\n",
    "    temp = temp.loc[article_list].sort_values(ascending=False) # 예측 점수가 높은 순서로 정렬\n",
    "    if len(group) < 5:\n",
    "        for _ in range(5 - len(group)):\n",
    "            new_rows.append({'userID': userID, 'articleID': temp.index[_], 'count': None}) # 부족한 행 만큼 새로운 행 추가\n",
    "\n",
    "# 새로운 행을 기존 데이터프레임에 추가\n",
    "df_freq = pd.concat([df_freq, pd.DataFrame(new_rows)], axis=0)\n",
    "\n",
    "# 정렬\n",
    "df_freq = df_freq.sort_values(by=['userID'], ignore_index=True)\n",
    "\n",
    "submission = df_freq[[\"userID\", \"articleID\"]].reset_index(drop=True)\n",
    "submission.to_csv(f'CF_alpha{alpha}.csv', index=False)\n",
    "\n",
    "submission"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
